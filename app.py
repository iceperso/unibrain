import streamlit as st
import easyocr
import numpy as np
import pdfplumber
import docx
from docx import Document
from pptx import Presentation
from PIL import Image
from googletrans import Translator
from transformers import pipeline
import io

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="UniBrain Pro Max", layout="wide", page_icon="ğŸ§ ")

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø£Ø¯Ø§Ø¡) ---
@st.cache_resource
def load_models():
    # ØªØ­Ù…ÙŠÙ„ Ù…Ø­Ø±Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±
    reader = easyocr.Reader(['ar', 'en'])
    # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ„Ø®ÙŠØµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ: ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø£ØµØºØ± Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± Ø¶Ø¹ÙŠÙØ§Ù‹)
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    # Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ±Ø¬Ù…Ø©
    translator = Translator()
    return reader, summarizer, translator

reader, summarizer, translator = load_models()

# --- 3. Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ---

def extract_text(file):
    """Ø¯Ø§Ù„Ø© Ø°ÙƒÙŠØ© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù"""
    text = ""
    file_name = file.name.lower()
    
    try:
        if file_name.endswith(('png', 'jpg', 'jpeg')):
            img = Image.open(file)
            res = reader.readtext(np.array(img), detail=0)
            text = " ".join(res)
            
        elif file_name.endswith('pdf'):
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                
        elif file_name.endswith('docx'):
            doc = docx.Document(file)
            for para in doc.paragraphs:
                text += para.text + "\n"
                
        elif file_name.endswith('pptx'):
            prs = Presentation(file)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        text += shape.text + "\n"
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù {file_name}: {e}")
        
    return text

def create_word_file(text, title="UniBrain Document"):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…Ù„Ù Word"""
    doc = Document()
    doc.add_heading(title, 0)
    doc.add_paragraph(text)
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---

st.title("ğŸ§  UniBrain Pro Max")
st.markdown("### Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„")

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3143/3143460.png", width=80)
    st.header("ğŸ“‚ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    uploaded_files = st.file_uploader(
        "Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ (ØµÙˆØ±ØŒ PDFØŒ WordØŒ PPT)", 
        type=['png', 'jpg', 'jpeg', 'pdf', 'docx', 'pptx'], 
        accept_multiple_files=True
    )
    st.info("ÙŠØ¯Ø¹Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµØŒ Ø§Ù„ØªÙ„Ø®ÙŠØµØŒ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø©.")

# --- 5. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ù…Ù„ ---

if uploaded_files:
    # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©
    if 'full_text' not in st.session_state or st.session_state.get('last_files_count') != len(uploaded_files):
        combined_text = ""
        with st.spinner('Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª...'):
            for file in uploaded_files:
                combined_text += f"\n--- Ù…Ø­ØªÙˆÙ‰ {file.name} ---\n"
                combined_text += extract_text(file)
        st.session_state.full_text = combined_text
        st.session_state.last_files_count = len(uploaded_files)

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø¥Ù„Ù‰ ØªØ¨ÙˆÙŠØ¨Ø§Øª
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©", "ğŸ§  Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°ÙƒÙŠ", "ğŸŒ Ø§Ù„ØªØ±Ø¬Ù…Ø©"])

    with tab1:
        st.subheader("Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬")
        edited_text = st.text_area("ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§:", st.session_state.full_text, height=400)
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "ğŸ’¾ ØªØ­Ù…ÙŠÙ„ ÙƒÙ…Ù„Ù Text", 
                data=edited_text, 
                file_name="UniBrain_Extract.txt"
            )
        with col2:
            word_data = create_word_file(edited_text)
            st.download_button(
                "ğŸ“ ØªØ­Ù…ÙŠÙ„ ÙƒÙ…Ù„Ù Word", 
                data=word_data, 
                file_name="UniBrain_Extract.docx"
            )

    with tab2:
        st.subheader("ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
        if st.button("Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ„Ø®ÙŠØµ"):
            if len(edited_text.strip()) > 50:
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                    # Ø£Ø®Ø° Ø£ÙˆÙ„ 2000 Ø­Ø±Ù Ù„ØªØ¬Ù†Ø¨ Ø¨Ø·Ø¡ Ø§Ù„Ø³ÙŠØ±ÙØ±
                    input_text = edited_text[:2000]
                    summary = summarizer(input_text, max_length=150, min_length=50, do_sample=False)
                    summary_result = summary[0]['summary_text']
                    st.success("Ø§Ù„Ø®Ù„Ø§ØµØ©:")
                    st.write(summary_result)
            else:
                st.warning("Ø§Ù„Ù†Øµ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØªÙ„Ø®ÙŠØµ.")

    with tab3:
        st.subheader("Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©")
        target_lang = st.radio("Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©:", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
        if st.button("ØªØ±Ø¬Ù… Ø§Ù„Ø¢Ù†"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©..."):
                dest = 'ar' if target_lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else 'en'
                # Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ 3000 Ø­Ø±Ù Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ¨Ø©
                translated = translator.translate(edited_text[:3000], dest=dest)
                st.info(translated.text)

else:
    # Ø´Ø§Ø´Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ Ø¹Ù†Ø¯ Ø¹Ø¯Ù… Ø±ÙØ¹ Ù…Ù„ÙØ§Øª
    st.markdown("---")
    st.markdown("<h2 style='text-align: center; color: #6c757d;'>ğŸ‘ˆ Ø§Ø¨Ø¯Ø£ Ø¨Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©</h2>", unsafe_allow_html=True)
        if file_name.endswith(('png', 'jpg', 'jpeg')):
            img = Image.open(file)
            res = reader.readtext(np.array(img), detail=0)
            text = " ".join(res)
            
        elif file_name.endswith('pdf'):
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                
        elif file_name.endswith('docx'):
            doc = docx.Document(file)
            for para in doc.paragraphs:
                text += para.text + "\n"
                
        elif file_name.endswith('pptx'):
            prs = Presentation(file)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        text += shape.text + "\n"
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù {file_name}: {e}")
        
    return text

def create_word_file(text, title="UniBrain Document"):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…Ù„Ù Word"""
    doc = Document()
    doc.add_heading(title, 0)
    doc.add_paragraph(text)
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---

st.title("ğŸ§  UniBrain Pro Max")
st.markdown("### Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„")

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3143/3143460.png", width=80)
    st.header("ğŸ“‚ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    uploaded_files = st.file_uploader(
        "Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ (ØµÙˆØ±ØŒ PDFØŒ WordØŒ PPT)", 
        type=['png', 'jpg', 'jpeg', 'pdf', 'docx', 'pptx'], 
        accept_multiple_files=True
    )
    st.info("ÙŠØ¯Ø¹Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµØŒ Ø§Ù„ØªÙ„Ø®ÙŠØµØŒ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø©.")

# --- 5. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ù…Ù„ ---

if uploaded_files:
    # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©
    if 'full_text' not in st.session_state or st.session_state.get('last_files_count') != len(uploaded_files):
        combined_text = ""
        with st.spinner('Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª...'):
            for file in uploaded_files:
                combined_text += f"\n--- Ù…Ø­ØªÙˆÙ‰ {file.name} ---\n"
                combined_text += extract_text(file)
        st.session_state.full_text = combined_text
        st.session_state.last_files_count = len(uploaded_files)

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø¥Ù„Ù‰ ØªØ¨ÙˆÙŠØ¨Ø§Øª
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©", "ğŸ§  Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°ÙƒÙŠ", "ğŸŒ Ø§Ù„ØªØ±Ø¬Ù…Ø©"])

    with tab1:
        st.subheader("Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬")
        edited_text = st.text_area("ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§:", st.session_state.full_text, height=400)
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "ğŸ’¾ ØªØ­Ù…ÙŠÙ„ ÙƒÙ…Ù„Ù Text", 
                data=edited_text, 
                file_name="UniBrain_Extract.txt"
            )
        with col2:
            word_data = create_word_file(edited_text)
            st.download_button(
                "ğŸ“ ØªØ­Ù…ÙŠÙ„ ÙƒÙ…Ù„Ù Word", 
                data=word_data, 
                file_name="UniBrain_Extract.docx"
            )

    with tab2:
        st.subheader("ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
        if st.button("Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ„Ø®ÙŠØµ"):
            if len(edited_text.strip()) > 50:
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                    # Ø£Ø®Ø° Ø£ÙˆÙ„ 2000 Ø­Ø±Ù Ù„ØªØ¬Ù†Ø¨ Ø¨Ø·Ø¡ Ø§Ù„Ø³ÙŠØ±ÙØ±
                    input_text = edited_text[:2000]
                    summary = summarizer(input_text, max_length=150, min_length=50, do_sample=False)
                    summary_result = summary[0]['summary_text']
                    st.success("Ø§Ù„Ø®Ù„Ø§ØµØ©:")
                    st.write(summary_result)
            else:
                st.warning("Ø§Ù„Ù†Øµ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØªÙ„Ø®ÙŠØµ.")

    with tab3:
        st.subheader("Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©")
        target_lang = st.radio("Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©:", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
        if st.button("ØªØ±Ø¬Ù… Ø§Ù„Ø¢Ù†"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©..."):
                dest = 'ar' if target_lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else 'en'
                # Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ 3000 Ø­Ø±Ù Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ¨Ø©
                translated = translator.translate(edited_text[:3000], dest=dest)
                st.info(translated.text)

else:
    # Ø´Ø§Ø´Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ Ø¹Ù†Ø¯ Ø¹Ø¯Ù… Ø±ÙØ¹ Ù…Ù„ÙØ§Øª
    st.markdown("---")
    st.markdown("<h2 style='text-align: center; color: #6c757d;'>ğŸ‘ˆ Ø§Ø¨Ø¯Ø£ Ø¨Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©</h2>", unsafe_allow_html=True)

# ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title("ğŸ§  UniBrain Pro Max")
st.markdown("### Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„Ø·Ù„Ø§Ø¨")

with st.sidebar:
    st.header("ğŸ“‚ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ (Ù…Ù„Ù PDF Ø£Ùˆ ØµÙˆØ±Ø©)", type=['pdf', 'png', 'jpg', 'jpeg'])

# Ø¹Ù†Ø¯ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø¹Ù…Ù„:
if uploaded_file is not None:
    with st.spinner('Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...'):
        extracted_text = ""
        
        try:
            # 1. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù PDF
            if uploaded_file.type == "application/pdf":
                with pdfplumber.open(uploaded_file) as pdf:
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            extracted_text += page_text + "\n"
            
            # 2. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù ØµÙˆØ±Ø© (Ù…Ù„Ø²Ù…Ø©)
            else:
                image = Image.open(uploaded_file)
                image_np = np.array(image)
                results = reader.readtext(image_np)
                extracted_text = " ".join([res[1] for res in results])
                
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø­Ø§ÙˆÙ„Ø© ÙØªØ­ Ø§Ù„Ù…Ù„Ù: {e}")

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        if extracted_text and extracted_text.strip():
            col1, col2 = st.columns(2)
            
            with col1:
                st.success("âœ… Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬")
                st.text_area("Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¹Ù„ÙŠÙ‡):", extracted_text, height=300)
            
            with col2:
                st.info("ğŸ“ Ø§Ù„Ù…Ù„Ø®Øµ")
                summary = summarize_text(extracted_text)
                st.write(summary)
                
                # Ø²Ø± Ø§Ù„ØªØ±Ø¬Ù…Ø©
                if st.button("ØªØ±Ø¬Ù… Ø§Ù„Ù…Ù„Ø®Øµ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© ğŸŒ"):
                    try:
                        translated = translator.translate(summary, dest='ar').text
                        st.success("**Ø§Ù„ØªØ±Ø¬Ù…Ø©:**")
                        st.write(translated)
                    except Exception as e:
                        st.error("Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ±Ø¬Ù…Ø© ØªÙˆØ§Ø¬Ù‡ Ø¶ØºØ·Ø§Ù‹ Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø¬Ø¯Ø¯Ø§Ù‹.")

            # Ø²Ø± ØªØ­Ù…ÙŠÙ„ Word
            st.divider()
            docx_file = create_docx(extracted_text)
            st.download_button(
                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ ÙƒÙ…Ù„Ù Word",
                data=docx_file,
                file_name="UniBrain_Result.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        else:
            st.warning("âš ï¸ Ø§Ù„Ù…Ù„Ù Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ ÙˆØ§Ø¶Ø­Ø©. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù€ PDF Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† ØµÙˆØ±ØŒ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹Ù‡Ø§ ÙƒØµÙˆØ± Ø¹Ø§Ø¯ÙŠØ©.")
else:
    st.info("ğŸ‘ˆ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø±ÙØ¹ Ù…Ù„ÙÙƒ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©.")    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    translator = Translator()
    return reader, summarizer, translator

reader, summarizer, translator = load_models()

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª ---
def extract_text(file, file_name):
    text = ""
    ext = file_name.split('.')[-1].lower()
    if ext in ['png', 'jpg', 'jpeg']:
        img = Image.open(file)
        res = reader.readtext(np.array(img), detail=0)
        text = " ".join(res)
    elif ext == 'pdf':
        pdf_reader = PyPDF2.PdfReader(file)
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
    elif ext == 'docx':
        doc = docx.Document(file)
        for para in doc.paragraphs:
            text += para.text + "\n"
    elif ext == 'pptx':
        prs = Presentation(file)
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    text += shape.text + "\n"
    return text

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
with st.sidebar:
    st.title("UniBrain Pro Max")
    uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ (ØµÙˆØ±ØŒ PDFØŒ WordØŒ PPT)", 
                                      type=['png', 'jpg', 'jpeg', 'pdf', 'docx', 'pptx'], 
                                      accept_multiple_files=True)

if uploaded_files:
    if 'full_text' not in st.session_state:
        st.session_state.full_text = ""
        for file in uploaded_files:
            st.session_state.full_text += extract_text(file, file.name)

    tab1, tab2 = st.tabs(["ğŸ“ Ø§Ù„Ù†Øµ", "ğŸ¤– Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"])
    with tab1:
        st.text_area("Ø§Ù„Ù…Ø­ØªÙˆÙ‰:", st.session_state.full_text, height=400)
    with tab2:
        if st.button("ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"):
            summary = summarizer(st.session_state.full_text[:1024], max_length=150, min_length=50, do_sample=False)
            st.success(summary[0]['summary_text'])
else:
    st.info("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡.")

def extract_text(file, file_name):
    """Ø¯Ø§Ù„Ø© Ø°ÙƒÙŠØ© ØªØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ÙˆØªØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Øµ Ù…Ù†Ù‡"""
    text = ""
    ext = file_name.split('.')[-1].lower()
    
    try:
        if ext in ['png', 'jpg', 'jpeg']:
            img = Image.open(file)
            res = reader.readtext(np.array(img), detail=0)
            text = " ".join(res)
            
        elif ext == 'pdf':
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
                
        elif ext == 'docx':
            doc = docx.Document(file)
            for para in doc.paragraphs:
                text += para.text + "\n"
                
        elif ext == 'pptx':
            prs = Presentation(file)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        text += shape.text + "\n"
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù {file_name}")
        
    return text

def create_word_file(text, title="Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ"):
    """Ø¯Ø§Ù„Ø© Ù„ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ù Word Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ­Ù…ÙŠÙ„"""
    doc = docx.Document()
    doc.add_heading(title, 0)
    doc.add_paragraph(text)
    
    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ØªÙ†Ø²ÙŠÙ„Ù‡
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3143/3143460.png", width=80)
    st.title("UniBrain Pro Max")
    st.markdown("ÙŠØ¯Ø¹Ù…: Ø§Ù„ØµÙˆØ±ØŒ PDFØŒ WordØŒ Ùˆ PowerPoint")
    st.write("---")
    
    # ØªØ­Ø¯ÙŠØ« Ø±Ø§ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„ÙŠØ¯Ø¹Ù… ÙƒÙ„ Ø§Ù„ØµÙŠØº
    uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù‡Ù†Ø§", 
                                      type=['png', 'jpg', 'jpeg', 'pdf', 'docx', 'pptx'], 
                                      accept_multiple_files=True)
    
    if uploaded_files:
        st.success(f"ØªÙ… Ø±ÙØ¹ {len(uploaded_files)} Ù…Ù„ÙØ§Øª")

# --- Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ---
if uploaded_files:
    if 'full_text' not in st.session_state or st.session_state.get('file_count') != len(uploaded_files):
        st.session_state.full_text = ""
        st.session_state.file_count = len(uploaded_files)
        
        with st.spinner('Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª...'):
            for file in uploaded_files:
                extracted = extract_text(file, file.name)
                st.session_state.full_text += f"\n--- Ù…Ø­ØªÙˆÙ‰ {file.name} ---\n" + extracted

    tab1, tab2, tab3 = st.tabs(["ğŸ“„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© ÙˆØ§Ù„ØªØµØ¯ÙŠØ±", "ğŸ§  Ø§Ù„Ø´Ø±Ø­ ÙˆØ§Ù„ØªÙ„Ø®ÙŠØµ", "ğŸŒ Ø§Ù„ØªØ±Ø¬Ù…Ø©"])

    with tab1:
        st.subheader("Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª")
        st.text_area("ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†Øµ ÙˆØªØ¹Ø¯ÙŠÙ„Ù‡ Ù‡Ù†Ø§:", st.session_state.full_text, height=300)
        
        st.markdown("### ğŸ“¥ ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù„ÙØ§Øª (Export)")
        col_dl1, col_dl2 = st.columns(2)
        with col_dl1:
            st.download_button(label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ ÙƒÙ…Ù„Ù Ù†ØµÙŠ (.txt)", 
                               data=st.session_state.full_text, 
                               file_name="UniBrain_Extract.txt", mime="text/plain")
        with col_dl2:
            word_file = create_word_file(st.session_state.full_text, "Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© - UniBrain")
            st.download_button(label="ğŸ“ ØªØ­Ù…ÙŠÙ„ ÙƒÙ…Ù„Ù Word (.docx)", 
                               data=word_file, 
                               file_name="UniBrain_Extract.docx", 
                               mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")
            st.caption("ÙŠÙ…ÙƒÙ†Ùƒ Ø±ÙØ¹ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Canva Ù„ØªØµÙ…ÙŠÙ…Ù‡.")

    with tab2:
        st.subheader("Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°ÙƒÙŠ")
        if st.button("ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ„Ø®ÙŠØµ"):
            if len(st.session_state.full_text.split()) > 30:
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰..."):
                    summary = summarizer(st.session_state.full_text[:2000], max_length=200, min_length=50, do_sample=False)
                    st.success("Ø§Ù„Ø®Ù„Ø§ØµØ©:")
                    st.write(summary[0]['summary_text'])
                    
                    # Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ„Ø®ÙŠØµ ÙƒÙ€ Word
                    sum_word = create_word_file(summary[0]['summary_text'], "Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°ÙƒÙŠ")
                    st.download_button("ğŸ“ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ„Ø®ÙŠØµ ÙƒÙ…Ù„Ù Word", data=sum_word, file_name="Summary.docx")
            else:
                st.warning("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹.")

    with tab3:
        st.subheader("Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©")
        target_lang = st.radio("Ø§Ø®ØªØ± Ù„ØºØ© Ø§Ù„ØªØ±Ø¬Ù…Ø©:", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
        if st.button("ØªØ±Ø¬Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰"):
            dest = 'ar' if target_lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else 'en'
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©..."):
                translated = translator.translate(st.session_state.full_text[:2000], dest=dest)
                st.info(translated.text)

else:
    # Ø´Ø§Ø´Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨
    st.markdown("<br><br><h2 style='text-align: center; color: #6c757d;'>ğŸ‘ˆ Ø§Ø¨Ø¯Ø£ Ø¨Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©</h2>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: #adb5bd;'>Ø§Ø±ÙØ¹ Ù…Ø­Ø§Ø¶Ø±Ø§ØªÙƒ Ø¨ØµÙŠØºØ© PDF, Word, PowerPoint Ø£Ùˆ Ø­ØªÙ‰ ØµÙˆØ± Ø§Ù„Ù…Ù„Ø§Ø²Ù….</p>", unsafe_allow_html=True)

    




