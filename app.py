import streamlit as st
import easyocr
import pdfplumber
from PIL import Image
import numpy as np
from googletrans import Translator
from docx import Document
from io import BytesIO

# Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.set_page_config(page_title="UniBrain Pro Max", layout="wide")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ØµÙˆØ± Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
@st.cache_resource
def load_ocr():
    return easyocr.Reader(['ar', 'en'])

reader = load_ocr()
translator = Translator()

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°ÙƒÙŠØ© (Ø³Ø±ÙŠØ¹Ø© ÙˆØªÙ†Ø§Ø³Ø¨ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ)
def summarize_text(text):
    if not text or len(text.strip()) == 0:
        return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ ÙƒØ§ÙÙŠ Ù„Ù„ØªÙ„Ø®ÙŠØµ."
    sentences = text.replace('\n', ' ').split('.')
    sentences = [s for s in sentences if len(s.strip()) > 5] # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙØ±Ø§ØºØ§Øª
    summary = ". ".join(sentences[:min(len(sentences), 5)]) # Ø£Ø®Ø° Ø£Ù‡Ù… 5 Ø¬Ù…Ù„
    return summary if len(sentences) > 3 else text

# Ø¯Ø§Ù„Ø© ØªØµØ¯ÙŠØ± Ù…Ù„Ù Ø§Ù„ÙˆÙˆØ±Ø¯
def create_docx(text):
    doc = Document()
    doc.add_paragraph(text)
    bio = BytesIO()
    doc.save(bio)
    return bio.getvalue()

# ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title("ğŸ§  UniBrain Pro Max")
st.markdown("### Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„Ø·Ù„Ø§Ø¨")

with st.sidebar:
    st.header("ğŸ“‚ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ (Ù…Ù„Ù PDF Ø£Ùˆ ØµÙˆØ±Ø©)", type=['pdf', 'png', 'jpg', 'jpeg'])

# Ø¹Ù†Ø¯ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø¹Ù…Ù„:
if uploaded_file is not None:
    with st.spinner('Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...'):
        extracted_text = ""
        
        try:
            # 1. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù PDF
            if uploaded_file.type == "application/pdf":
                with pdfplumber.open(uploaded_file) as pdf:
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            extracted_text += page_text + "\n"
            
            # 2. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù ØµÙˆØ±Ø© (Ù…Ù„Ø²Ù…Ø©)
            else:
                image = Image.open(uploaded_file)
                image_np = np.array(image)
                results = reader.readtext(image_np)
                extracted_text = " ".join([res[1] for res in results])
                
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø­Ø§ÙˆÙ„Ø© ÙØªØ­ Ø§Ù„Ù…Ù„Ù: {e}")

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ø°Ø§ ØªÙ… Ø¥ÙŠØ¬Ø§Ø¯ Ù†Øµ
        if extracted_text and extracted_text.strip():
            col1, col2 = st.columns(2)
            
            with col1:
                st.success("âœ… Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬")
                st.text_area("Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¹Ù„ÙŠÙ‡):", extracted_text, height=300)
            
            with col2:
                st.info("ğŸ“ Ø§Ù„Ù…Ù„Ø®Øµ")
                summary = summarize_text(extracted_text)
                st.write(summary)
                
                # Ø²Ø± Ø§Ù„ØªØ±Ø¬Ù…Ø©
                if st.button("ØªØ±Ø¬Ù… Ø§Ù„Ù…Ù„Ø®Øµ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© ğŸŒ"):
                    try:
                        translated = translator.translate(summary, dest='ar').text
                        st.success("**Ø§Ù„ØªØ±Ø¬Ù…Ø©:**")
                        st.write(translated)
                    except Exception as e:
                        st.error("Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ±Ø¬Ù…Ø© ØªÙˆØ§Ø¬Ù‡ Ø¶ØºØ·Ø§Ù‹ Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø¬Ø¯Ø¯Ø§Ù‹.")

            # Ø²Ø± ØªØ­Ù…ÙŠÙ„ Word
            st.divider()
            docx_file = create_docx(extracted_text)
            st.download_button(
                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ ÙƒÙ…Ù„Ù Word",
                data=docx_file,
                file_name="UniBrain_Result.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        else:
            # Ø±Ø³Ø§Ù„Ø© Ø°ÙƒÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù€ PDF Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† ØµÙˆØ± ÙˆÙ„ÙŠØ³ Ù†ØµØ§Ù‹
            st.warning("âš ï¸ ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØŒ Ù„ÙƒÙ† ÙŠØ¨Ø¯Ùˆ Ø£Ù†Ù‡ 'ØµÙˆØ±Ø© Ù…Ù…Ø³ÙˆØ­Ø© Ø¶ÙˆØ¦ÙŠØ§Ù‹' Ø¯Ø§Ø®Ù„ PDF Ø£Ùˆ Ø£Ù†Ù‡ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ ÙˆØ§Ø¶Ø­Ø©. ÙŠØ±Ø¬Ù‰ ØªØµÙˆÙŠØ± Ø§Ù„ÙˆØ±Ù‚Ø© ÙˆØ±ÙØ¹Ù‡Ø§ ÙƒÙ€ 'ØµÙˆØ±Ø©' Ø¹Ø§Ø¯ÙŠØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† PDF Ù„ÙƒÙŠ ÙŠÙ‚Ø±Ø£Ù‡Ø§ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.")
else:
    st.info("ğŸ‘ˆ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø±ÙØ¹ Ù…Ù„ÙÙƒ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©.")
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    translator = Translator()
    return reader, summarizer, translator

reader, summarizer, translator = load_models()

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª ---
def extract_text(file, file_name):
    text = ""
    ext = file_name.split('.')[-1].lower()
    if ext in ['png', 'jpg', 'jpeg']:
        img = Image.open(file)
        res = reader.readtext(np.array(img), detail=0)
        text = " ".join(res)
    elif ext == 'pdf':
        pdf_reader = PyPDF2.PdfReader(file)
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
    elif ext == 'docx':
        doc = docx.Document(file)
        for para in doc.paragraphs:
            text += para.text + "\n"
    elif ext == 'pptx':
        prs = Presentation(file)
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    text += shape.text + "\n"
    return text

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
with st.sidebar:
    st.title("UniBrain Pro Max")
    uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ (ØµÙˆØ±ØŒ PDFØŒ WordØŒ PPT)", 
                                      type=['png', 'jpg', 'jpeg', 'pdf', 'docx', 'pptx'], 
                                      accept_multiple_files=True)

if uploaded_files:
    if 'full_text' not in st.session_state:
        st.session_state.full_text = ""
        for file in uploaded_files:
            st.session_state.full_text += extract_text(file, file.name)

    tab1, tab2 = st.tabs(["ğŸ“ Ø§Ù„Ù†Øµ", "ğŸ¤– Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"])
    with tab1:
        st.text_area("Ø§Ù„Ù…Ø­ØªÙˆÙ‰:", st.session_state.full_text, height=400)
    with tab2:
        if st.button("ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"):
            summary = summarizer(st.session_state.full_text[:1024], max_length=150, min_length=50, do_sample=False)
            st.success(summary[0]['summary_text'])
else:
    st.info("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡.")

def extract_text(file, file_name):
    """Ø¯Ø§Ù„Ø© Ø°ÙƒÙŠØ© ØªØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ÙˆØªØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Øµ Ù…Ù†Ù‡"""
    text = ""
    ext = file_name.split('.')[-1].lower()
    
    try:
        if ext in ['png', 'jpg', 'jpeg']:
            img = Image.open(file)
            res = reader.readtext(np.array(img), detail=0)
            text = " ".join(res)
            
        elif ext == 'pdf':
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
                
        elif ext == 'docx':
            doc = docx.Document(file)
            for para in doc.paragraphs:
                text += para.text + "\n"
                
        elif ext == 'pptx':
            prs = Presentation(file)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        text += shape.text + "\n"
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù {file_name}")
        
    return text

def create_word_file(text, title="Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ"):
    """Ø¯Ø§Ù„Ø© Ù„ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ù Word Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ­Ù…ÙŠÙ„"""
    doc = docx.Document()
    doc.add_heading(title, 0)
    doc.add_paragraph(text)
    
    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ØªÙ†Ø²ÙŠÙ„Ù‡
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3143/3143460.png", width=80)
    st.title("UniBrain Pro Max")
    st.markdown("ÙŠØ¯Ø¹Ù…: Ø§Ù„ØµÙˆØ±ØŒ PDFØŒ WordØŒ Ùˆ PowerPoint")
    st.write("---")
    
    # ØªØ­Ø¯ÙŠØ« Ø±Ø§ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„ÙŠØ¯Ø¹Ù… ÙƒÙ„ Ø§Ù„ØµÙŠØº
    uploaded_files = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù‡Ù†Ø§", 
                                      type=['png', 'jpg', 'jpeg', 'pdf', 'docx', 'pptx'], 
                                      accept_multiple_files=True)
    
    if uploaded_files:
        st.success(f"ØªÙ… Ø±ÙØ¹ {len(uploaded_files)} Ù…Ù„ÙØ§Øª")

# --- Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ---
if uploaded_files:
    if 'full_text' not in st.session_state or st.session_state.get('file_count') != len(uploaded_files):
        st.session_state.full_text = ""
        st.session_state.file_count = len(uploaded_files)
        
        with st.spinner('Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª...'):
            for file in uploaded_files:
                extracted = extract_text(file, file.name)
                st.session_state.full_text += f"\n--- Ù…Ø­ØªÙˆÙ‰ {file.name} ---\n" + extracted

    tab1, tab2, tab3 = st.tabs(["ğŸ“„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© ÙˆØ§Ù„ØªØµØ¯ÙŠØ±", "ğŸ§  Ø§Ù„Ø´Ø±Ø­ ÙˆØ§Ù„ØªÙ„Ø®ÙŠØµ", "ğŸŒ Ø§Ù„ØªØ±Ø¬Ù…Ø©"])

    with tab1:
        st.subheader("Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª")
        st.text_area("ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†Øµ ÙˆØªØ¹Ø¯ÙŠÙ„Ù‡ Ù‡Ù†Ø§:", st.session_state.full_text, height=300)
        
        st.markdown("### ğŸ“¥ ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù„ÙØ§Øª (Export)")
        col_dl1, col_dl2 = st.columns(2)
        with col_dl1:
            st.download_button(label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ ÙƒÙ…Ù„Ù Ù†ØµÙŠ (.txt)", 
                               data=st.session_state.full_text, 
                               file_name="UniBrain_Extract.txt", mime="text/plain")
        with col_dl2:
            word_file = create_word_file(st.session_state.full_text, "Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© - UniBrain")
            st.download_button(label="ğŸ“ ØªØ­Ù…ÙŠÙ„ ÙƒÙ…Ù„Ù Word (.docx)", 
                               data=word_file, 
                               file_name="UniBrain_Extract.docx", 
                               mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")
            st.caption("ÙŠÙ…ÙƒÙ†Ùƒ Ø±ÙØ¹ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Canva Ù„ØªØµÙ…ÙŠÙ…Ù‡.")

    with tab2:
        st.subheader("Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°ÙƒÙŠ")
        if st.button("ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ„Ø®ÙŠØµ"):
            if len(st.session_state.full_text.split()) > 30:
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰..."):
                    summary = summarizer(st.session_state.full_text[:2000], max_length=200, min_length=50, do_sample=False)
                    st.success("Ø§Ù„Ø®Ù„Ø§ØµØ©:")
                    st.write(summary[0]['summary_text'])
                    
                    # Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ„Ø®ÙŠØµ ÙƒÙ€ Word
                    sum_word = create_word_file(summary[0]['summary_text'], "Ø§Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø°ÙƒÙŠ")
                    st.download_button("ğŸ“ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ„Ø®ÙŠØµ ÙƒÙ…Ù„Ù Word", data=sum_word, file_name="Summary.docx")
            else:
                st.warning("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹.")

    with tab3:
        st.subheader("Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©")
        target_lang = st.radio("Ø§Ø®ØªØ± Ù„ØºØ© Ø§Ù„ØªØ±Ø¬Ù…Ø©:", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
        if st.button("ØªØ±Ø¬Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰"):
            dest = 'ar' if target_lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else 'en'
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©..."):
                translated = translator.translate(st.session_state.full_text[:2000], dest=dest)
                st.info(translated.text)

else:
    # Ø´Ø§Ø´Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨
    st.markdown("<br><br><h2 style='text-align: center; color: #6c757d;'>ğŸ‘ˆ Ø§Ø¨Ø¯Ø£ Ø¨Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©</h2>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: #adb5bd;'>Ø§Ø±ÙØ¹ Ù…Ø­Ø§Ø¶Ø±Ø§ØªÙƒ Ø¨ØµÙŠØºØ© PDF, Word, PowerPoint Ø£Ùˆ Ø­ØªÙ‰ ØµÙˆØ± Ø§Ù„Ù…Ù„Ø§Ø²Ù….</p>", unsafe_allow_html=True)

    

